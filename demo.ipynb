{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SE(nn.Module):\n",
    "    def __init__(self, in_ch):\n",
    "        super(SE, self).__init__()\n",
    "        self.se = nn.Sequential(\n",
    "            nn.Linear(in_ch, in_ch // 8, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_ch // 8, in_ch, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.size()) > 3:\n",
    "            x = F.adaptive_avg_pool2d(x, 1).squeeze()\n",
    "        sc = x\n",
    "        #print(sc.shape)\n",
    "        return self.se(x) * sc + sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 两层卷积的cbr\n",
    "class double_conv(nn.Module):\n",
    "    '''(conv => BN => ReLU) * 2'''\n",
    "\n",
    "    def __init__(self, in_ch, out_ch, stride=1, use_se=False, bottleneck=False):\n",
    "        super(double_conv, self).__init__()\n",
    "        self.use_se = use_se\n",
    "        self.bottleneck = bottleneck\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_ch, out_channels=out_ch, kernel_size=3, stride=stride, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=out_ch, out_channels=out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=out_ch, out_channels=out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch)\n",
    "        )\n",
    "\n",
    "        if self.use_se:\n",
    "            self.se = SE(out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        sc = x\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        if self.use_se:\n",
    "            x = self.se(x)\n",
    "\n",
    "        x += sc\n",
    "        x = F.relu(x, inplace=True)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通道变换操作\n",
    "class inconv(nn.Module):\n",
    "    '''\n",
    "    inconv only changes the number of channels\n",
    "    '''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(inconv, self).__init__()\n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 下采样 \n",
    "class down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, use_se=False):\n",
    "        super(down, self).__init__()\n",
    "        self.mpconv = double_conv(in_ch, out_ch, stride=2, use_se=use_se)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mpconv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 32, 32])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1,32,64,64)\n",
    "x.shape\n",
    "model_d = down(32, 32)\n",
    "out = model_d(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 128, 128])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2 = model_d(x)\n",
    "out2.shape#256->128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# upsample\n",
    "class double_conv(nn.Module):\n",
    "    '''(conv => BN => ReLU) * 2'''\n",
    "\n",
    "    def __init__(self, in_ch, out_ch, stride=1, use_se=False, bottleneck=False):\n",
    "        super(double_conv, self).__init__()\n",
    "        self.use_se = use_se\n",
    "        self.bottleneck = bottleneck\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_ch, out_channels=out_ch, kernel_size=3, stride=stride, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=out_ch, out_channels=out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=out_ch, out_channels=out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch)\n",
    "        )\n",
    "\n",
    "        if self.use_se:\n",
    "            self.se = SE(out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        sc = x\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        if self.use_se:\n",
    "            x = self.se(x)\n",
    "\n",
    "        x += sc\n",
    "        x = F.relu(x, inplace=True)\n",
    "        return x\n",
    "\n",
    "class up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, bilinear=False, op=\"none\", use_se=False):\n",
    "        super(up, self).__init__()\n",
    "        self.bilinear = bilinear\n",
    "        self.op = op\n",
    "        self.mixup_ratio = 0.95\n",
    "        assert op in [\"concat\", \"none\", \"add\", 'mix']\n",
    "\n",
    "        self.conv = double_conv(in_ch, out_ch, use_se=use_se)\n",
    "\n",
    "    def forward(self, x1, x2=None):\n",
    "        if x2 is not None:#非空\n",
    "            if torch.is_tensor(x2):\n",
    "                x1 = F.interpolate(x1, x2.size()[-2:], mode='bilinear', align_corners=False)\n",
    "            else:\n",
    "                x1 = F.interpolate(x1, x2, mode='bilinear', align_corners=False)\n",
    "        else:\n",
    "            x1 = F.interpolate(x1, scale_factor=2,  mode='bilinear', align_corners=False)\n",
    "\n",
    "        if self.op == \"concat\":\n",
    "            x = torch.cat([x2, x1], dim=1)\n",
    "        elif self.op == 'add':\n",
    "            x = x1 + x2\n",
    "        else:\n",
    "            x = x1\n",
    "            \n",
    "        x = self.conv(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 128, 128])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.randn(1, 32, 128, 128)\n",
    "x2 = torch.randn(1, 64, 128, 128) \n",
    "x1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 256, 256])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up_model = up(32,64)\n",
    "out1 = up_model(x1)\n",
    "out1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_model = up(96,64,op=\"concat\")\n",
    "# up_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 128, 128])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = up_model(x1,x2)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 10.0, 'b': 0.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 10\n",
    "re = {'a': 0., 'b':0.}\n",
    "re['a'] += a\n",
    "re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch = 200\n",
    "a = (epoch - 200) / (400 - 200)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch = 500\n",
    "b = (epoch - 400) / (600 - 400)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class inconv(nn.Module):\n",
    "    '''\n",
    "    inconv only changes the number of channels\n",
    "    '''\n",
    "\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(inconv, self).__init__()\n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 128, 128])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1,1,128,128)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 128, 128])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inconv = inconv(1, 32)\n",
    "out = model_inconv(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inconv(\n",
      "  (conv): double_conv(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_inconv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_channel = 128 * 4 * 4 \n",
    "attention = nn.MultiheadAttention(memory_channel, 8)\n",
    "# attn_output, attn_output_weights = attention(query, key, value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10, 512])\n",
      "torch.Size([32, 10, 512])\n",
      "torch.Size([10, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 假设我们有一个序列长度为10，嵌入维度为512，我们想要实现8个头的多头注意力\n",
    "sequence_length = 10\n",
    "embedding_dim = 512\n",
    "num_heads = 8\n",
    "batch_size = 32\n",
    "\n",
    "# 实例化多头注意力模块\n",
    "multihead_attn = nn.MultiheadAttention(embed_dim=embedding_dim, num_heads=num_heads)\n",
    "\n",
    "# 创建一些随机数据来模拟输入\n",
    "# query, key, value 通常是一样的，但也可以是不同的\n",
    "query = torch.rand(batch_size, sequence_length, embedding_dim)\n",
    "key = torch.rand(batch_size, sequence_length, embedding_dim)\n",
    "value = torch.rand(batch_size, sequence_length, embedding_dim)\n",
    "\n",
    "# 应用多头注意力\n",
    "attn_output, attn_output_weights = multihead_attn(query, key, value)\n",
    "\n",
    "# 输出的形状将是 (batch_size, sequence_length, embed_dim)\n",
    "print(query.shape)\n",
    "print(attn_output.shape)\n",
    "\n",
    "# 输出权重的形状将是 (batch_size, num_heads, sequence_length, sequence_length)\n",
    "print(attn_output_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 512])\n",
      "torch.Size([1, 256, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 假设我们的图像是224x224，我们将其分割成16个14x14的块\n",
    "image_size = 224\n",
    "patch_size =14\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "embedding_dim = 512\n",
    "num_heads = 8\n",
    "batch_size = 1\n",
    "\n",
    "\n",
    "# 将图像分割成块，并线性嵌入\n",
    "class PatchEmbed(nn.Module):\n",
    "    def __init__(self, img_size=224, patch_size=14, in_chans=3, \n",
    "    embed_dim=512):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.proj = nn.Conv2d(\n",
    "            in_chans, embed_dim, kernel_size=patch_size, \n",
    "            stride=patch_size\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)  # (B, E, H, W)\n",
    "        x = x.flatten(2)  # (B, E, N)\n",
    "        x = x.transpose(1, 2)  # (B, N, E)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 实例化图像分割和嵌入模块\n",
    "patch_embed = PatchEmbed(\n",
    "    img_size=image_size, patch_size=patch_size, in_chans=3, embed_dim=embedding_dim\n",
    ")\n",
    "\n",
    "# 创建一个随机图像\n",
    "img = torch.rand(batch_size, 3, image_size, image_size)\n",
    "print(img.shape)\n",
    "\n",
    "# 将图像转换为序列\n",
    "patches = patch_embed(img)\n",
    "print(patches.shape)\n",
    "# 实例化多头注意力模块\n",
    "multihead_attn = nn.MultiheadAttention(embed_dim=embedding_dim, num_heads=num_heads)\n",
    "\n",
    "# 应用多头注意力\n",
    "attn_output, attn_output_weights = multihead_attn(patches, patches, patches)\n",
    "\n",
    "# 输出的形状将是 (batch_size, num_patches, embed_dim)\n",
    "print(attn_output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_shrink_relu(input, lambd=0., epsilon=1e-12):\n",
    "    output = (F.relu(input - lambd) * input) / (torch.abs(input - lambd) + epsilon)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0000,  0.1000,  3.0000],\n",
      "        [ 4.0000,  5.0000,  6.0000]])\n",
      "tensor([[-0., 0., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[-1, 0.1, 3], [4, 5, 6]])\n",
    "\n",
    "print(a)\n",
    "output = hard_shrink_relu(a,lambd=2.)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch中的topk的用法，能够返回tensor中维度的最值和索引\n",
    "a = torch.tensor([[-1, 3, 0.1], [4, 5, 6]])\n",
    "value, index = a.topk(1, dim=1, largest=True)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.],\n",
       "        [6.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = value[:,[-1]]# 高级索引，取最后一列\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数组:\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "\n",
      "所有行的最后一列:\n",
      "[[3]\n",
      " [6]\n",
      " [9]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "thres = np.array([[1, 2, 3],\n",
    "                 [4, 5, 6],\n",
    "                 [7, 8, 9]])\n",
    "\n",
    "print(\"原始数组:\")\n",
    "print(thres)\n",
    "# 高级索引最后一行\n",
    "thres_last_column = thres[:, [-1]]\n",
    "\n",
    "print(\"\\n所有行的最后一列:\")\n",
    "print(thres_last_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=(128//2)//2**4\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a=256 * (4 * (2 ** (0 + 1)) // 2) ** 2\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_window(x, window_size, stride=1, padding=0):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x: (B, C, H, W)\n",
    "        window_size (int): window size\n",
    "\n",
    "    Returns:\n",
    "        windows: (B*N, C, ws, ws)\n",
    "    \"\"\"\n",
    "    B, C, W, H = x.shape\n",
    "    windows = F.unfold(x, window_size, padding=padding, stride=stride) # B, C * ws ** 2, N, #of windows\n",
    "    windows = windows.view(B, C, window_size**2, -1) #   B, C, ws**2, N\n",
    "    windows = windows.permute(0, 3, 1, 2).contiguous().view(-1, C, window_size, window_size) # B*N, C, ws, ws\n",
    "    \n",
    "    return windows\n",
    "def window_reverse(windows, window_size, H, W):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        windows: (num_windows*B, C, window_size, window_size)\n",
    "        window_size (int): Window size\n",
    "        H (int): Height of image\n",
    "        W (int): Width of image\n",
    "\n",
    "    Returns:\n",
    "        x: (B, C, H, W)\n",
    "    \"\"\"\n",
    "    num_windows = H * W / window_size / window_size\n",
    "    B = int(windows.shape[0] / num_windows)\n",
    "    x = windows.view(B, H // window_size, W // window_size, -1, window_size, window_size)\n",
    "    x = x.permute(0, 3, 1, 4, 2, 5).contiguous().view(B, -1, H, W)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= torch.randn(1,3,128,128)\n",
    "x.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 64, 64])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 128//2\n",
    "# x, window_size=W//self.num_patch, stride=W//self.num_patch, padding=0\n",
    "out = make_window(x, window_size=a, stride=a, padding=0)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, w, h * self.num_patch, w * self.num_patch\n",
    "out2 =window_reverse(out, 64, 64*2, 64*2)\n",
    "x=out2\n",
    "# x = window_reverse(x,128,128*2,128*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 判别器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDiscriminator(nn.Module):\n",
    "    def __init__(self, num_in_ch=1, size=4, num_layers = 4, inplace=True):\n",
    "        super(SimpleDiscriminator, self).__init__()\n",
    "\n",
    "        self.size = size\n",
    "\n",
    "        keep_stats = True\n",
    "\n",
    "        out_channels = 16\n",
    "        layers = [\n",
    "            nn.Conv2d(num_in_ch, out_channels, 5, 2, 2, bias=True),\n",
    "            #nn.BatchNorm2d(16, track_running_stats=keep_stats), # this maybe required\n",
    "            nn.LeakyReLU(0.2, inplace=inplace),\n",
    "        ]\n",
    "        \n",
    "        for ilayer in range(num_layers):\n",
    "            in_channels = out_channels\n",
    "            out_channels = min(16 * (2 ** (ilayer + 1)), 256)\n",
    "            layers.extend([\n",
    "                nn.Conv2d(in_channels, out_channels, 5, 2, 2, bias=True),\n",
    "                nn.BatchNorm2d(out_channels, track_running_stats=keep_stats),\n",
    "                nn.LeakyReLU(0.2, inplace=inplace),\n",
    "            ])\n",
    "\n",
    "        self.conv_model = nn.Sequential(*layers)\n",
    "\n",
    "        self.regressor = nn.Linear(out_channels * size * size, 1)\n",
    "\n",
    "    def forward(self, img):\n",
    "        B = img.size(0)\n",
    "\n",
    "        x = self.conv_model(img) # B, 128, W/16, H/16\n",
    "\n",
    "        x = x.view(B, -1)\n",
    "        x = self.regressor(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 128, 128])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= torch.randn(1,3,128,128)\n",
    "# CONFIG.num_in_ch, size=CONFIG.size, num_layers=CONFIG.num_layers\n",
    "model_dic = SimpleDiscriminator(num_in_ch=3, size=4, num_layers=4)\n",
    "out_dic = model_dic(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1174]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Maduo(nums, c_nums, zuo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ratf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
